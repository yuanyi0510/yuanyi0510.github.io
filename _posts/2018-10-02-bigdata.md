---
layout: post
title: "Single Node Setup"
date: 2018-10-02  
tag: "hadoop" 
---

# Single Node Setup
[官网地址](http://hadoop.apache.org/docs/r2.5.2/hadoop-project-dist/hadoop-common/SingleCluster.html)
## 1. 本地模式
## 2.伪分布式模式
*************************  本地模式    ****************************

![2-1](https://img-blog.csdn.net/20181012173715537?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3l1YW55aTA1MDE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
-  . grep input output 'dfs[a-z.]+'  运行mapreduce的例子，input是当前目录下的文件夹；output是运行输出结果储存的地方，并且在当前目录下没有。'dfs[a-z.]+'是检索的参数	
  ![2-2](https://img-blog.csdn.net/20181012173945214?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3l1YW55aTA1MDE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
  可以看到运行成功后，目录中出现了output。output中有_success文件说明成功。运算结果在part-r-00000中，结果如图2-2所示。
  - bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0.jar wordcount  wcinput wcoutput   
    查看wcinput中wc.input文件中单词的数量,运行结果如下：
  ![2-3](https://img-blog.csdn.net/20181012174229802?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3l1YW55aTA1MDE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
*******
 *********************** 伪分布式******************************
 
1. hadoop的端口号一般为8020
2. namenode存储的元数据
3. $ bin/hdfs namenode -format    namenode格式化
4. sbin/hadoop-daemon.sh start namenode 启动namenode
4. sbin/hadoop-daemon.sh start datanode 启动datanode。
5. 在根目录下会出现log文件夹，说明启动成功
6. 访问192.168.220.128:50070
- 具体步骤：
-![2-4](https://img-blog.csdn.net/20181012174653705?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3l1YW55aTA1MDE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

## YARN on Single Node

- 步骤如下：
![2-5](https://img-blog.csdn.net/20181012174822403?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3l1YW55aTA1MDE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
***********

### 启动方式
1. 服务逐一启动
 hdfs：sbin/hadoop-daemon.sh start|stop namenode|datanode|secondarynamenode
yarn:sbin/yarn-daemon.sh start|stop resourcemanager|nodemanager
mapreduce: sbin/mr-historyserver-daemon.sh start|stop history
2. 各个模块启动:(配置ssh无密钥登陆)
hdfs:sbin/start-dfs.sh
yarn:sbin/start-yarn.sh
3. 一起启动：
 	sbin/start-all.sh
## 配置文件
#### HDFS

- NameNode：core-site.xml文件

```
<property>
     <name>fs.defaultFS</name>
     <value>hdfs://localhost:9000</value>———》指定了namenode运行的机器hostname:8020
</property>
```

   
   
- DataNode：slaves文件

- SecondaryNamenode：hdfs-site.xml

```
   <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>"hostname":50090</value>————》指定了namenode运行的机器
    </property>
```

#### YARN
- ResourceManager：yarn-site.xml

```
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hsotname</value>
    </property>
```

- NodeManager：slaves文件

- MapReduce：mapred-site.xml
- HistoryServer：mapred-site.xml

```
<property>
        <name>mapreduce.jobhistory.address</name>
        <value>hsotname:10020</value>
</property>
<property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>hsotname:19888</value>
</property>
```




