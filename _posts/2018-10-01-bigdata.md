---
layout: post
title: "大数据Hadoop2.x"
date: 2018-10-01  
tag: "hadoop" 
---
# 大数据Hadoop2.x

 - hadoop用来分析存储网路数据
 - MapReduce：对海量数据的处理、分布式。
     思想————> 分而治之，大数据集分为小的数据集，每个数据集进行逻辑业务处理合并统计数据结果（reduce）
     运行模式：本地模式和yarn模式
     input——>map——>shuffle——>reduce——>output
       shuffle：将结果进行排序
   HDFS：存储海量数据
  ### 分布式
- 数据安全性——>副本数据（一般保存3份）
 -  数据是以block的方式进行存储的
  ### YARN：分布式资源管理框架
 -  管理整个集群的资源（内存，CPU核数）
 -  分配调度集群的资源
  ### ResouceManager 
  - 整个集群的资源管理和调度
  ### NodeManager 
  - 管理每个节点的资源和调度
  ### MapReduce ：分而治之
- map：分。跟别计算每个block的结果
- reduce：合并结果
   
### NameNode主节点
- 存储文件系统的元数据（文件名、文件目录结构、文件属性）。数据流不经过存储在内存（进程），读取速度比较快
  ### Datanodes从节点
  - 本地文件系统存储文件块数据，以及块数据的校验和
   - 本地磁盘——>fsimage：镜像文件	edites：编辑日志
  ### SecondaryNameNode 
  - 辅助namenode工作，2.0版本中默认存在的。周期性的合并两个文件
  ===========================================
- rpm -qa|grep java 查看linux当前版本
 -  rpm -e --nodeps  卸载当前Java
-   echo ${变量}   显示变量的路径。如echo ${JAVA_HOME} 显示JAVA_HOME的安装路径
****
### 常见的hdfs命令
 -  bin/hdfs dfs -ls 文件目录	查看目录下有哪些文件。不加路径，直接查看用户主目录/user/root
- bin/hdfs dfs -rm -R 文件目录（文件名）删除文件。如果直接输入文件名，则删除用户主目录下的文件
- bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0.jar wordcount /user/root/mapreduce/wordcount/input/ /user/root/mapreduce/wordcount/output 	mapreduce应用提交到yarn上面。mapreduce的输出结果在outpu文件，文件夹之前是不能存在的
- bin/hdfs dfs -cat 文件目录 	读取文件
- bin/hdfs dfs -text  文件目录	读取文件，将要读取的文件变成文本文件
- bin/hdfs dfs namenode -formate	namenode格式化
- sbin/mr-jobhistory-daemon.sh start historyserver	启动历史服务器
#### hadoop默认提供3个mapreduce程序，用于基本测试
- taragen：深层数据
- terasort：对数据排序
- taravalidate：验证排序结果